# BrainIB+

## Interpretable Diagnosis of Schizophrenia Using Graph-Based Brain Network Information Bottleneck

This is the BrianIB+ demo for the BSNIP and UCLA dataset, BrianIB+ is also known as BrainIB V2.

This README.md is for all readers.
 
### Contents
- [Overall Methods](#getting-started)
  - [Data Preprocessing](#data-preprocessing)
  - [The Architecture of model](#the-architecture-of-model)
- [Implementation](#implementation)
- [Results](#results)
- [Interpretable analysis](#interpretable-analysis)
- [Getting Started](#getting-started)
  - [Configuration requirements](#configuration-requirements)
  - [Step by step](#step-by-step)
- [File Directory Description](#file-directory-description)

### Overall Methods

#### Data Preprocessing
 In this study, two datasets are used: the public dataset acquired from UCLA Consortium for Neuropsychiatric Phenomics(UCLA)(https://exhibits.stanford.edu/data/catalog/mg599hw5271), and
 the dataset from the Tri-Institutional Georgia State University/Georgia Institute of Technology/Emory University Center for Translational Research in Neuroimaging and Data Science (TReNDS)\footnote(https://trendscenter.org/data/), US (BSNIP)(https://github.com/TianzhengHU/BrainIB_node). 

**![](data_preprocessing.png)**

**Figure 1 data preprocessing** 
The resting-state fMRI raw data are preprocessed and then parcellated into regions of interest (ROIs) according to the Group ICA atlas and the map to the automated anatomical labeling (AAL) atlas. The functional connectivity (FC) matrices are calculated using Pearson correlation between ROIs. From the FC we construct the brain functional graph G = {A, X}, where A is the graph adjacency matrix characterizing the graph structure and X is the node feature matrix. Specifically, A is a binarized FC matrix, where only the top 20-percentile absolute values of the correlations of the matrix are transformed into ones, while the rest are transformed into zeros.  For node feature $X$, $X_{k}$ for node $k$ can be defined as $X_{k}=\left [ \rho_{k1},\dots, \rho_{kn}\right ] ^{\text{T}}$ , where $\rho_{kl}$ is the Pearson’s correlation coefficient for node $k$ and node $l$. Note that, we only consider functional connectivity values as node features, which is common in brain network analysis [4]. Finally, the functional graph is fed to BrainIB for psychiatric classification.



#### The Architecture of model

<p align="center">
  <figure>
    <img src="datapreprocessing-overview_framework.png" alt="Image 1" width="700"/>
  </figure>
</p>

**Figure 2 data preprocessing** BrainIB+ including a Subgraph Generator, a Graph Encoder, and a Mutual Information Estimator

<p align="center">
  <figure>
    <img src="datapreprocessing-subgraph_generator.png" alt="Image 2" width="700"/>
  </figure>
</p>

**Figure 3 subgraph generator** Given the input graph structure data G, the subgraph is generated along with the node assignment S, indicating whether a specific node belongs to $G_{sub}$ or $\overline{G_{sub}}$. 
Softmax to the output of MLP to ensure the nodes are either in or out of the subgraph followed by GCN layers. The MLP utilized in this context is a two-layer fully connected neural network. We employed it to continuously reduce the dimensionality of nodes from 8 to 2.
S is a matrix in shape $N\times 2$, where N is the number of nodes. When S is well-learned, the assignment of nodes is supposed to saturate to 0/1. 
The representation of $G_{sub}$ that used to predict the graph label can be obtained by taking the first row of $S^TX^l$.



<p align="center">
  <figure>
    <img src="datapreprocessing-graph-encoder.png" alt="Image 2" width="700"/>
  </figure>
</p>

**Figure 4 graph encoder** The object of the graph encoder is to encode the graph structure data G = (X, A) as vertical embedding. It is applied on both the whole graph data G and the subgraph data $G_{sub}$ generated by the Subgraph Generator.
After two layers of GIN, we obtain the representation H of the original nodes feature matrix X. 
We add a second-order pooling (SOPOOL) on the H followed by dropout and normalization operation, defined as: 
```math
g_n = \mathrm{flatten} \left( \mathrm{SOPOOL}_{bi-linear} \left(GIN (A, X) \right) \right)
```

### Implementation

The graph IB objective includes two mutual information terms:

```math
{\mathrm{min}} I(G_{sub}, G) - \beta I (G_{sub},Y)
```

Minimizing $-I (G_{sub}, Y)$ encourages $G_{sub}$ is most predictable to graph label Y. Maximizing the $I(G_{sub}, G)$ encourages the subgraph sampling keep as much information from the original graph as possible.



### Results

<table border="1">
  <caption>TABLE I: Experiment performance of all baseline models and BrainIB+ model on the single-site datasets, which means training and testing on the same dataset.</caption>
  <thead>
    <tr>
      <th rowspan="2">Single-site DATASET</th>
      <th colspan="5">Traditional Model</th>
      <th colspan="5">Graph Model</th>
    </tr>
    <tr>
      <th>SVM</th>
      <th>SVM-E</th>
      <th>Decision Tree</th>
      <th>KNN</th>
      <th>AdaBoost</th>
      <th>GIN</th>
      <th>GAT</th>
      <th>BrainIB</th>
      <th>BrainIB+</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BSNIP</td>
      <td>0.715</td>
      <td>0.611</td>
      <td>0.568</td>
      <td>0.651</td>
      <td>0.625</td>
      <td>0.704</td>
      <td>0.696</td>
      <td>0.722</td>
      <td>0.748</td>
    </tr>
    <tr>
      <td>UCLA</td>
      <td>0.727</td>
      <td>0.667</td>
      <td>0.515</td>
      <td>0.545</td>
      <td>0.667</td>
      <td>0.706</td>
      <td>0.765</td>
      <td>0.765</td>
      <td>0.765</td>
    </tr>
  </tbody>
</table>

<br>

<table border="1">
  <caption>TABLE II: Experiment performance of all baseline models and BrainIB+ model on a multi-site dataset. SVM-E performs best when training on the BSNIP datasetand testing on the UCLA dataset when BrainIB+ performs best when training on UCLA and testing on the BSNIP dataset.</caption>
  <thead>
    <tr>
      <th rowspan="2">Multi-site DATASET</th>
      <th colspan="5">Traditional Model</th>
      <th colspan="5">Graph Model</th>
    </tr>
    <tr>
      <th>SVM</th>
      <th>SVM-E</th>
      <th>Decision Tree</th>
      <th>KNN</th>
      <th>AdaBoost</th>
      <th>GIN</th>
      <th>GAT</th>
      <th>BrainIB</th>
      <th>BrainIB+</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BSNIP to UCLA</td>
      <td>0.576</td>
      <td>0.697</td>
      <td>0.424</td>
      <td>0.667</td>
      <td>0.455</td>
      <td>0.588</td>
      <td>0.412</td>
      <td>0.585</td>
      <td>0.689</td>
    </tr>
    <tr>
      <td>UCLA to BSNIP</td>
      <td>0.489</td>
      <td>0.537</td>
      <td>0.463</td>
      <td>0.445</td>
      <td>0.459</td>
      <td>0.487</td>
      <td>0.478</td>
      <td>0.443</td>
      <td>0.548</td>
    </tr>
  </tbody>
</table>



### Interpretable analysis

<p align="center">
  <figure>
    <img src="multi-site_BrainIB+.png" alt="Image 2" width="700"/>
  </figure>
</p>

**Figure 5 interpretable analysis result** BrainIB+ model demonstrated node preferences across datasets from both BSNIP and UCLA datasets during multi-site training(BSNIP to UCLA). The nodes with top probabilities were selected by the well-trained BrainIB+'s Subgraph Generator on the BSNIP dataset and the UCLA dataset individually. The 5 common nodes including Supp\_Motor\_Area\_L, Calcarine\_R, Occipital\_Inf\_R, Fusiform\_R, Postcentral\_R are the top five brain regions.

### Getting Started

Please ensure that the device has a working environment。

#### Configuration requirements

1. Activate your environment
2. Install packages
```sh
pip install -r requirements.txt
```

#### **Step by step**

1. Clone the repo
```sh
git clone git@github.com:TianzhengHU/BrainIB_coding.git
```

2. Download the example dataset from Google Drive.
The datasets used in this project are public avaliable. To facilitate testing, we make the preprocessed dataset publicly available on Google drive.
Please download dataset files: **UCLA.mat** and **BSNIP.mat** from link:
```
 https://drive.google.com/drive/folders/1ca9-nxsldpN3Cam_bGX6odce1VlOt96J?usp=share_link).
```
Put them under the "real_data" folder.


3. Run the code
```sh
python SGSIB_main.py
```


### File Directory Description

```
BrainIB_GIB 
├── /SGSIB/
│  ├── /model/
│  ├── sub_graph_generator.py
│  ├── sub_node_generator.py
│  └── utils.py
├── /baseline_data/
│  ├── /data/
│  └── baseline_main.py
├── /real_data/
│  ├── /Utils_preprocessing/
│  │  ├── BrainNet_index_map.xlsx
│  │  ├── BSNIP_new_id.xlsx
│  │  ├── ICNs_v2.xlsx
│  │  ├── closest_map_points.xlsx
│  │  ├── UCLA_preprocessing.py
│  │  └── Map_groupICA_and_BrainNet_map.py
│  ├── analysis_data.py
│  └── create_dataset.txt
├── Graph_network_main.py
├── SGSIB_main.py
├── Traditional_main.py
├── Visualization.py
├── requirements.txt
└── README.md

```
